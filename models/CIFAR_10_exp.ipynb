{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7Bu_phhB7Jt"
   },
   "source": [
    "Dint use **UDA and smoothening**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11S6cDwUWrs5"
   },
   "source": [
    "###1. SetUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt98Z6ArW0Rb"
   },
   "source": [
    "####1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RQ2RMza-WfaG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98zgJmOhW3eq"
   },
   "source": [
    "####1.2 Device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38
    },
    "id": "JJeT8OcZWueo",
    "outputId": "8a549c30-0bb4-42f2-9392-453506466c22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlg9QZ07jI0-"
   },
   "source": [
    "####1.3 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "9KIhTKHgjIW3"
   },
   "outputs": [],
   "source": [
    "MU = 11.5\n",
    "BATCH_SIZE = 128\n",
    "SEED = 42\n",
    "EPOCHS = 15\n",
    "BETA_ZERO = 8\n",
    "a = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inYhRQe_XED-"
   },
   "source": [
    "###2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHYs-QdHXGkj"
   },
   "source": [
    "####2.1 Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "j8qBEnDrW_0v"
   },
   "outputs": [],
   "source": [
    "def get_cifar10_data():\n",
    "  from torchvision import datasets\n",
    "  from torchvision.datasets import ImageFolder\n",
    "\n",
    "  train_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "  )\n",
    "\n",
    "  test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "  )\n",
    "  return (train_data , test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fBgWhFs1Xhe9",
    "outputId": "57f0d524-3141-4fd8-cb84-f9b9b3580753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: data\n",
       "     Split: Train,\n",
       " Dataset CIFAR10\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data , test_data = get_cifar10_data()\n",
    "train_data , test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFOjjoPPYWC7"
   },
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "J-rPtTifYVlH"
   },
   "outputs": [],
   "source": [
    "def visualize(dir):\n",
    "  import random\n",
    "  random_index = random.randint(0, len(dir) - 1)\n",
    "  image, label = dir[random_index]\n",
    "  plt.figure(figsize=(10,5))\n",
    "  plt.title(label)\n",
    "  plt.imshow(image)\n",
    "  plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "1bktIrgrXqru",
    "outputId": "d3f25f78-ba5c-45c0-af0c-8b57575b1c4f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'bool' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0da035624a79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-c4d7161f7daf>\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/env2/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36maxis\u001b[0;34m(*v, **kwargs)\u001b[0m\n\u001b[1;32m   2433\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env2/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36maxis\u001b[0;34m(self, *v, **kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1714\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'v must contain [xmin xmax ymin ymax]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'bool' has no len()"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJNzS529ad5x"
   },
   "source": [
    "#### 2.2 Organize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "l1bRNdK5ZJ33"
   },
   "outputs": [],
   "source": [
    "def load_batches(file_path):\n",
    "  import os\n",
    "  import pickle\n",
    "  with open(file_path, 'rb') as fo:\n",
    "    batch = pickle.load(fo, encoding='bytes')\n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ej69vQqma9o1",
    "outputId": "99fd2664-d925-45ba-b259-77f722cc3469"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'num_cases_per_batch': 10000,\n",
       " b'label_names': [b'airplane',\n",
       "  b'automobile',\n",
       "  b'bird',\n",
       "  b'cat',\n",
       "  b'deer',\n",
       "  b'dog',\n",
       "  b'frog',\n",
       "  b'horse',\n",
       "  b'ship',\n",
       "  b'truck'],\n",
       " b'num_vis': 3072}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_path = 'data/cifar-10-batches-py/batches.meta'\n",
    "meta = load_batches(meta_path)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ryXHLhgebM0P"
   },
   "outputs": [],
   "source": [
    "def create_classification_directory(input_dir,output_dir,subdirectory):\n",
    "  import os\n",
    "  os.makedirs(output_dir, exist_ok=True)\n",
    "  for label_id, class_name in enumerate(subdirectory):\n",
    "    class_name = class_name.decode('utf-8')\n",
    "    class_dir = os.path.join(output_dir, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Y7kfCuewcnZ6"
   },
   "outputs": [],
   "source": [
    "### Train directory\n",
    "input_dir = 'data/cifar-10-batches-py'\n",
    "output_dir = 'cifar-10-dataset'\n",
    "subdirectory = meta[b'label_names']\n",
    "create_classification_directory(input_dir,output_dir,subdirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DC_r5FQddFxj"
   },
   "outputs": [],
   "source": [
    "### Test directory\n",
    "input_dir = 'data/cifar-10-batches-py'\n",
    "output_dir = 'test'\n",
    "subdirectory = meta[b'label_names']\n",
    "create_classification_directory(input_dir,output_dir,subdirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "szovQIl0dily"
   },
   "outputs": [],
   "source": [
    "### Copy train Data\n",
    "def Copy_train_Images(input_dir,output_dir):\n",
    "  import os\n",
    "  for batch_id in range(1, 6):\n",
    "    batch_data = load_batches(os.path.join(input_dir, f'data_batch_{batch_id}'))\n",
    "    for i, (image, label) in enumerate(zip(batch_data[b'data'], batch_data[b'labels'])):\n",
    "      class_name = meta[b'label_names'][label].decode('utf-8')\n",
    "      image = image.reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "      image_filename = f'{batch_id}_{i + 1}.png'\n",
    "      output_path = os.path.join(output_dir, class_name, image_filename)\n",
    "      plt.imsave(output_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LID5gRyDeaCN"
   },
   "outputs": [],
   "source": [
    "output_dir = 'cifar-10-dataset'\n",
    "input_dir = 'data/cifar-10-batches-py'\n",
    "Copy_train_Images(input_dir,output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_MeR7_RLempR"
   },
   "outputs": [],
   "source": [
    "def Images_in_directory(input_dir):\n",
    "  from pathlib import Path\n",
    "  dir = Path(input_dir)\n",
    "  num_items = len(list(dir.glob('*/*.png')))\n",
    "  print(f\"Number of items in {dir} directory: {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkigCmike499",
    "outputId": "43175794-bdb3-4f43-d73e-e185293b1d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in cifar-10-dataset directory: 50000\n"
     ]
    }
   ],
   "source": [
    "Images_in_directory('cifar-10-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6pfaxA3gfRgd"
   },
   "outputs": [],
   "source": [
    "### Copy test Data\n",
    "def Copy_test_Images(input_dir,output_dir):\n",
    "  import os\n",
    "  batch_data = load_batches(os.path.join(input_dir, 'test_batch'))\n",
    "  for i, (image, label) in enumerate(zip(batch_data[b'data'], batch_data[b'labels'])):\n",
    "        class_name = meta[b'label_names'][label].decode('utf-8')\n",
    "        image = image.reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "        image_filename = f'{i + 1}.png'\n",
    "        output_path = os.path.join(output_dir, class_name, image_filename)\n",
    "        plt.imsave(output_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_3E1QBnGfyZk"
   },
   "outputs": [],
   "source": [
    "output_dir = 'test'\n",
    "input_dir = 'data/cifar-10-batches-py'\n",
    "Copy_test_Images(input_dir,output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZX7DlkvegB1U",
    "outputId": "c2c84778-982a-4380-c986-f6b5585668f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in test directory: 10000\n"
     ]
    }
   ],
   "source": [
    "Images_in_directory('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yGkPRSlrhArY"
   },
   "outputs": [],
   "source": [
    "def simple_dataset(input_dir):\n",
    "  from torchvision import datasets\n",
    "  data = datasets.ImageFolder(root=input_dir)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEOoGWSbhSNt",
    "outputId": "6aef0257-d2a2-4c47-88bd-12db2c02a4fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 50000\n",
       "    Root location: cifar-10-dataset"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = simple_dataset('cifar-10-dataset')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieHdUDlRhygR"
   },
   "source": [
    "####2.3 Labeled and Unlabeled Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7qU6_sUhsgF",
    "outputId": "06dadbf1-e55a-4548-d47c-0bfdde28c730"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_ratio = 1/(MU+1)\n",
    "labeled_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "dFwWgE2OjeFi"
   },
   "outputs": [],
   "source": [
    "def get_subdirectories(parent_dir):\n",
    "  import os\n",
    "  from pathlib import Path\n",
    "  for subdirectory in os.listdir(parent_dir):\n",
    "    subdirectory_path = os.path.join(parent_dir, subdirectory)\n",
    "    if os.path.isdir(subdirectory_path):\n",
    "        print(\"Subdirectory:\", subdirectory_path)\n",
    "  parent_dir = Path(parent_dir)\n",
    "  subdirectories = [subdir for subdir in parent_dir.iterdir() if subdir.is_dir()]\n",
    "  return subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWNPnQtvjmhE",
    "outputId": "803c2386-7f93-4d9a-b059-a359bf79a403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subdirectory: cifar-10-dataset/truck\n",
      "Subdirectory: cifar-10-dataset/horse\n",
      "Subdirectory: cifar-10-dataset/ship\n",
      "Subdirectory: cifar-10-dataset/frog\n",
      "Subdirectory: cifar-10-dataset/bird\n",
      "Subdirectory: cifar-10-dataset/deer\n",
      "Subdirectory: cifar-10-dataset/dog\n",
      "Subdirectory: cifar-10-dataset/automobile\n",
      "Subdirectory: cifar-10-dataset/airplane\n",
      "Subdirectory: cifar-10-dataset/cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PosixPath('cifar-10-dataset/truck'),\n",
       " PosixPath('cifar-10-dataset/horse'),\n",
       " PosixPath('cifar-10-dataset/ship'),\n",
       " PosixPath('cifar-10-dataset/frog'),\n",
       " PosixPath('cifar-10-dataset/bird'),\n",
       " PosixPath('cifar-10-dataset/deer'),\n",
       " PosixPath('cifar-10-dataset/dog'),\n",
       " PosixPath('cifar-10-dataset/automobile'),\n",
       " PosixPath('cifar-10-dataset/airplane'),\n",
       " PosixPath('cifar-10-dataset/cat')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_directories = get_subdirectories('cifar-10-dataset')\n",
    "sub_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "5B46H6B6jWcL"
   },
   "outputs": [],
   "source": [
    "def l_u_split(seed,source,l,u,ratio):\n",
    "  import numpy as np\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "\n",
    "  import os\n",
    "  import random\n",
    "  from pathlib import Path\n",
    "\n",
    "  source_dir = Path(source)\n",
    "  labeled_dir = Path(l)\n",
    "  unlabeled_dir = Path(u)\n",
    "\n",
    "  labeled_dir.mkdir(parents=True, exist_ok=True)\n",
    "  unlabeled_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  split_ratio = ratio\n",
    "\n",
    "\n",
    "  for class_name in os.listdir(source_dir):\n",
    "    class_dir = source_dir / class_name\n",
    "\n",
    "    labeled_class_dir = labeled_dir / class_name\n",
    "    labeled_class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    unlabeled_class_dir = unlabeled_dir / class_name\n",
    "    unlabeled_class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    image_files = list(class_dir.glob(\"*.png\"))\n",
    "\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    num_labeled = int(len(image_files) * split_ratio)\n",
    "    num_unlabeled = len(image_files) - num_labeled\n",
    "\n",
    "    for i in range(num_labeled):\n",
    "        src_path = image_files[i]\n",
    "        dest_path = labeled_class_dir / src_path.name\n",
    "        src_path.rename(dest_path)\n",
    "\n",
    "    for i in range(num_labeled, num_labeled + num_unlabeled):\n",
    "        src_path = image_files[i]\n",
    "        dest_path = unlabeled_class_dir / src_path.name\n",
    "        src_path.rename(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "DVPS7t0Dk_hd"
   },
   "outputs": [],
   "source": [
    "l_u_split(SEED,'cifar-10-dataset','labeled','unlabeled',labeled_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5balCIb9lMOZ",
    "outputId": "5d187ec3-df57-44e1-c126-9658da169092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in labeled directory: 14794\n"
     ]
    }
   ],
   "source": [
    "Images_in_directory('labeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOeWkqHpnbgN",
    "outputId": "49ce3da7-685b-429a-e8e6-ea7680c72704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in unlabeled directory: 49928\n"
     ]
    }
   ],
   "source": [
    "Images_in_directory('unlabeled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeiS3N5onioi"
   },
   "source": [
    "####2.4 Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4Ah3up0cneHE"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import RandomHorizontalFlip,RandomAffine\n",
    "\n",
    "transform = transforms.Compose([transforms.AutoAugment(),\n",
    "                               transforms.RandAugment(),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomAutocontrast(p= 0.5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.2),\n",
    "    transforms.RandomResizedCrop(size=(32,32)),\n",
    "    transforms.RandomEqualize(p= 0.5),\n",
    "    transforms.RandomInvert(p=0.5),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=0.5),\n",
    "    transforms.RandomAffine(degrees=12.5,translate=[0.5,0.5],shear=[0.5,0.5]),\n",
    "    transforms.RandomRotation(degrees=12.5),\n",
    "    transforms.RandomPosterize(bits=8,p= 0.5),\n",
    "    transforms.RandomSolarize(threshold = 0.5,p= 0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be2Jdqyzor_M"
   },
   "source": [
    "####2.5 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "peJoGONfn20Z"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "labeled_dir = 'labeled'\n",
    "unlabeled_dir = 'unlabeled'\n",
    "test_dir = 'test'\n",
    "\n",
    "labeled_data = ImageFolder(root=labeled_dir,transform=transform)\n",
    "unlabeled_data = ImageFolder(root=unlabeled_dir,transform=simple_transform)\n",
    "unlabeled_data_augmented = ImageFolder(root=unlabeled_dir,transform=transform)\n",
    "test_data = ImageFolder(root=test_dir,transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvuhH2AioosY"
   },
   "source": [
    "####2.6 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "huT02c4ZoUeK"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "labeled_train_loader = DataLoader(labeled_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "unlabeled_train_loader = DataLoader(unlabeled_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "unlabeled_train_loader_augmented = DataLoader(unlabeled_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOzuuM0Lomds",
    "outputId": "db19ca3b-7e8c-4517-e0f2-19da3ac4c7ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled:116 | Unlabeled_Augmented:391 | Unlabeled:391 | Test:79\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labeled:{len(labeled_train_loader)} | Unlabeled_Augmented:{len(unlabeled_train_loader_augmented)} | Unlabeled:{len(unlabeled_train_loader)} | Test:{len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHYlHspBo7cb"
   },
   "source": [
    "###3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fjOeLHq7qGR",
    "outputId": "4650b0f0-ef6d-40d0-97d7-fd244b4e6ff4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "def conv_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        init.constant_(m.weight, 1)\n",
    "        init.constant_(m.bias, 0)\n",
    "\n",
    "class wide_basic(nn.Module):\n",
    "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
    "        super(wide_basic, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out += self.shortcut(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Wide_ResNet(nn.Module):\n",
    "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
    "        super(Wide_ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        assert ((depth-4)%6 ==0), 'Wide-resnet depth should be 6n+4'\n",
    "        n = (depth-4)/6\n",
    "        k = widen_factor\n",
    "\n",
    "        print('| Wide-Resnet %dx%d' %(depth, k))\n",
    "        nStages = [16, 16*k, 32*k, 64*k]\n",
    "\n",
    "        self.conv1 = conv3x3(3,nStages[0])\n",
    "        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n",
    "        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n",
    "        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n",
    "        self.linear = nn.Linear(nStages[3], num_classes)\n",
    "\n",
    "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
    "        strides = [stride] + [1]*(int(num_blocks)-1)\n",
    "        layers = []\n",
    "\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
    "            self.in_planes = planes\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net=Wide_ResNet(28, 2, 0.3, 10)\n",
    "    y = net(Variable(torch.randn(1,3,32,32)))\n",
    "\n",
    "    print(y.size())\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiljZ_XCpNL5"
   },
   "source": [
    "###4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Anr8tpt1pQu-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdT7wbqhrYGB"
   },
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "  correct = torch.eq(y_true.to(device), y_pred.to(device)).sum().item()\n",
    "  acc = (correct / len(y_pred)) * 100\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smcEF8dWIJcM"
   },
   "outputs": [],
   "source": [
    "def plot_loss_curves(results):\n",
    "    train_loss = results[\"train_loss\"]\n",
    "    test_loss = results[\"model_test_loss\"]\n",
    "\n",
    "    accuracy = results[\"train_acc\"]\n",
    "    test_accuracy = results[\"ema_test_acc\"]\n",
    "\n",
    "    epochs = range(len(results[\"train_loss\"]))\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label=\"train_loss\")\n",
    "    plt.plot(epochs, test_loss, label=\"test_loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
    "    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4Brl6FDKL9s"
   },
   "source": [
    "####Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dEzB4aYooEn",
    "outputId": "816f2183-7c34-4d27-ad39-2f5f9f883968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 28x2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wide_ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer1): Sequential(\n",
       "    (0): wide_basic(\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): wide_basic(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): wide_basic(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): wide_basic(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): wide_basic(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "    )\n",
       "    (1): wide_basic(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): wide_basic(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): wide_basic(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): wide_basic(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "    )\n",
       "    (1): wide_basic(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): wide_basic(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): wide_basic(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
       "  (linear): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "\n",
    "from torchvision import models\n",
    "model = Wide_ResNet(28, 2, 0.3, 10).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = torchvision.models.efficientnet_b0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_b0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5,inplace=True),\n",
    "    nn.Linear(in_features=1280,out_features=10,bias=True)\n",
    ")\n",
    "model=model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "XeFcx1L4pKHh"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d34BGElOL_Iw",
    "outputId": "b5c4b0c0-dc01-4229-8b31-0ad6a7657f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i tensor(1.)\n",
      "a tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "i = torch.tensor(i,dtype=torch.float32)\n",
    "a = 8\n",
    "a = torch.tensor(a,dtype=torch.float32)\n",
    "print(\"i\",i)\n",
    "print(\"a\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "CVcyMHes65-C"
   },
   "outputs": [],
   "source": [
    "clipping_value = 0.8\n",
    "label_smoothing_constant = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HiPsH-8lKgVk",
    "outputId": "e0e73ee8-2a49-45eb-efb7-be5571c87e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per epoch : 10.007911392405063\n",
      "Loss_1:2.1125617027282715 \n",
      "Loss_2:0.9512028694152832 \n"
     ]
    }
   ],
   "source": [
    "epochs = EPOCHS\n",
    "beta_zero = BETA_ZERO\n",
    "num_epochs = epochs\n",
    "labeled_batches = iter(labeled_train_loader)\n",
    "unlabeled_batches = iter(unlabeled_train_loader)\n",
    "unlabeled_batches_augmented = iter(unlabeled_train_loader_augmented)\n",
    "test_batches = iter(test_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    acc = 0\n",
    "    model.train()\n",
    "    loss_per_epoch_1 = 0\n",
    "    loss_per_epoch_2 = 0\n",
    "    for _ in range(len(unlabeled_train_loader)):\n",
    "        try:\n",
    "            labeled_images, labels = next(labeled_batches)\n",
    "        except StopIteration:\n",
    "            labeled_batches = iter(labeled_train_loader)\n",
    "            labeled_images, labels = next(labeled_batches)\n",
    "\n",
    "        try:\n",
    "            unlabeled_images, _ = next(unlabeled_batches)\n",
    "        except StopIteration:\n",
    "            unlabeled_batches = iter(unlabeled_train_loader)\n",
    "            unlabeled_images, _ = next(unlabeled_batches)\n",
    "\n",
    "        try:\n",
    "            unlabeled_images_augmented, _ = next(unlabeled_batches_augmented)\n",
    "        except StopIteration:\n",
    "            unlabeled_batches_augmented = iter(unlabeled_train_loader_augmented)\n",
    "            unlabeled_images_augmented, _ = next(unlabeled_batches_augmented)\n",
    "\n",
    "\n",
    "        # print(\"Unlabeled Image Tensor : \", unlabeled_images_augmented)\n",
    "        unlabeled_logits_augmented = model(unlabeled_images_augmented.to(device)).to(device)\n",
    "        # print(\"Unlabeled Image Logits Tensor : \", unlabeled_logits_augmented)\n",
    "        unlabeled_logits = model(unlabeled_images.to(device)).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "                    pseudo_labels = torch.argmax(torch.softmax(unlabeled_logits, dim=1), dim=1).to(device)\n",
    "\n",
    "        \n",
    "        labeled_logits = model(labeled_images.to(device)).to(device)\n",
    "\n",
    "        loss_1 = nn.CrossEntropyLoss(label_smoothing = label_smoothing_constant)(unlabeled_logits_augmented,pseudo_labels)\n",
    "        loss_old  = nn.CrossEntropyLoss()(labeled_logits.to(device),labels.to(device)).to(device)\n",
    "\n",
    "        #1st pass\n",
    "        optimizer.zero_grad()\n",
    "        loss_1.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clipping_value)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        new_labeled_logits = model(labeled_images.to(device)).to(device)\n",
    "        loss_ce_y = nn.CrossEntropyLoss()(new_labeled_logits,labels.to(device)).to(device).detach()\n",
    "\n",
    "        new_unlabeled_logits = model(unlabeled_images.to(device)).to(device)\n",
    "        new_unlabeled_logits_augmented = model(unlabeled_images_augmented.to(device)).to(device)\n",
    "        # print(\"new_unlabeled_logits\", new_unlabeled_logits)\n",
    "        # print(\"new_unlabeled_logits_augmented\", new_unlabeled_logits_augmented)\n",
    "        BETA_K = beta_zero * torch.min(i,((epoch+1)/a))\n",
    "\n",
    "        loss_partial = BETA_K * torch.sum(-(torch.softmax(new_unlabeled_logits,dim=1)) * torch.log1p(torch.softmax(new_unlabeled_logits_augmented,dim=1)), dim=0).mean()\n",
    "        loss_uda = loss_ce_y + loss_partial\n",
    "        # print(\"loss_ce_y:\", loss_ce_y)\n",
    "        # print(\"loss_partial:\", loss_partial)\n",
    "        with torch.no_grad():\n",
    "                    new_pseudo_labels = torch.argmax(torch.softmax(new_unlabeled_logits,dim=1), dim=1).to(device)\n",
    "\n",
    "\n",
    "        change = loss_old.detach() - loss_ce_y.detach()\n",
    "        loss_mpl = ((change)* (nn.CrossEntropyLoss()(new_unlabeled_logits,new_pseudo_labels)))\n",
    "        # print(\"change : \",change )\n",
    "        # print(\"The updated loss term in the end : \", nn.CrossEntropyLoss()(new_unlabeled_logits,new_pseudo_labels))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "#         print(f\"Loss_OLD:{loss_old} \")\n",
    "#         print(f\"Loss_NEW:{loss_ce_y} \")\n",
    "        # print(\"Loss_mpl:\",loss_mpl)\n",
    "        (loss_uda + loss_mpl).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clipping_value)\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_per_epoch_1 += loss_1\n",
    "        loss_per_epoch_2 += loss_uda + loss_mpl\n",
    "\n",
    "    model.eval()\n",
    "    for _ in range(len(test_loader)):\n",
    "      try:\n",
    "          test_images, test_labels = next(test_batches)\n",
    "      except StopIteration:\n",
    "          test_batches = iter(test_loader)\n",
    "          test_images, test_labels = next(test_batches)\n",
    "\n",
    "      test_logits = model(test_images.to(device))\n",
    "      pred_labels = torch.argmax(torch.softmax(test_logits,dim=1).to(device),dim=1).to(device)\n",
    "      acc += accuracy_fn(test_labels, pred_labels)\n",
    "\n",
    "    print(\"Accuracy per epoch :\", acc/len(test_loader))\n",
    "    print(f\"Loss_1:{loss_per_epoch_1/len(unlabeled_train_loader)} \")\n",
    "    print(f\"Loss_2:{loss_per_epoch_2/len(unlabeled_train_loader)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THa2qmN9G8L5"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "AxjrM9UsPEkM"
   },
   "outputs": [],
   "source": [
    "arr = torch.tensor([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3o34TCtPP7I",
    "outputId": "8d376cba-67b4-4389-ff51-873c5328e4fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 7, 9])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = arr.sum(dim=0)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rwpm18pJ9TT"
   },
   "source": [
    "####CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZOyCq_NKFAi"
   },
   "source": [
    "####EMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "8walGodwH_YA"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformer_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-86b388f8f09a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'transformer_model' is not defined"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(transformer_model.parameters(),lr=0.03,weight_decay=1e-4,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_cq24TBH2je"
   },
   "outputs": [],
   "source": [
    "t_results,t_ema = phase1(transformer_model,labeled_train_loader,unlabeled_train_loader,optimizer,test_loader,\n",
    "           confidence_threshold = threshold,MU=MU,loss_fn=loss_fn,epochs=EPOCHS,t_max=60,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sqvOI9fJf9N"
   },
   "outputs": [],
   "source": [
    "#plot_loss_curves(t_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9cD6LuyKRjz"
   },
   "source": [
    "####Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-acr3_ETt_5S"
   },
   "source": [
    "####Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wruEkjwjt_O1"
   },
   "outputs": [],
   "source": [
    "def predictions(model1,model2,test_loader):\n",
    "  results ={\"model1\":[],\n",
    "            \"model2\":[]\n",
    "  }\n",
    "  test_batches = iter(test_loader)\n",
    "  model1.eval()\n",
    "  model2.eval()\n",
    "  for _ in range(len(test_loader)):\n",
    "        try:\n",
    "            test_images, labels = next(test_batches)\n",
    "        except StopIteration:\n",
    "            test_batches = iter(test_loader)\n",
    "            test_images, labels = next(test_batches)\n",
    "\n",
    "        test_outputs1 = model1(test_images.to(device))\n",
    "        model1_label = torch.argmax(torch.softmax(model1(test_images.to(device)), dim=1), dim=1).to(device)\n",
    "\n",
    "        test_outputs2 = model2(test_images.to(device))\n",
    "        model2_label = torch.argmax(torch.softmax(model2(test_images.to(device)), dim=1), dim=1).to(device)\n",
    "\n",
    "  results[\"model1\"].append(model1_label)\n",
    "  results[\"model2\"].append(model2_label)\n",
    "  print(f\"Model1:{model1_label} Model2:{model2_label} Label:{labels}\")\n",
    "  return (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORV6-Y7eHXzC"
   },
   "outputs": [],
   "source": [
    "final_results = predictions(cnn_ema,t_ema,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCpT9iJDH1Cf"
   },
   "source": [
    "###Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-tq-fkuHnkT"
   },
   "outputs": [],
   "source": [
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "    from pathlib import Path\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_save_path = target_dir_path / model_name\n",
    "\n",
    "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(),\n",
    "             f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HHWax-LH204"
   },
   "outputs": [],
   "source": [
    "save_model(cnn_ema,'models','cnn_ema.pth')\n",
    "save_model(t_ema,'models','t_ema.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hDwn7IrJFAs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
